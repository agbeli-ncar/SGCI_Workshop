{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Parsing Module\n",
    "### Overview\n",
    "\n",
    "<div class=\"logos\"><img src=\"../Resources/media_assets/Twitter_Logo_Blue.png\" width=\"200x\" align=\"right\"></div> \n",
    "<p>\n",
    "In the current age, big data is a rapidly growing field that scales with our ability to collect it. With widespread internet connectivity, data can be collected and distributed from private industry, instruments and sensors, and \"digitizing\" historical data. By processing all the data collected, we can advance fields such as social science, physical science, health, and business.\n",
    "<br><br>\n",
    "In this module you will utilize data from the social media platform Twitter. The dataset is too large to analyze by hand, so a Python code will be used to aggregate, process, and present the data in a manner that is understandable by humans.\n",
    "\n",
    "</p>\n",
    "\n",
    "### Agenda\n",
    "- Overview and applications\n",
    "- Import libraries\n",
    "- Import data in Pandas dataframe\n",
    "- Sort data\n",
    "- Count data\n",
    "- Plot data\n",
    "\n",
    "## Libraries Used\n",
    "- **Pandas** - A Python data analysis library \n",
    "- **Matplotlib** - A Python library for creating visualizations\n",
    "<!--- Numpy -->\n",
    "\n",
    "## Dataset\n",
    "We will use data extracted from Twitter. The data spans from December 2019 - February 2020 and is based on tweets concerning COVID-19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 1 - Find the top 10 tweets from the dataset \n",
    "\n",
    "#import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "## View the Pandas methods available. We will use read_csv.\n",
    "#---(Command to view Pandas methods)\n",
    "\n",
    "## Import data & create a Pandas dataframe object named df\n",
    "#---df=pd.read_csv('path_to_file/filename.csv') \n",
    "\n",
    "\n",
    "## Print attributes and methods of df we will be using sort and head\n",
    "#---(Command to view dataframe object attributes and methods)\n",
    "\n",
    "## View the headers of the dataframe to see what is in it\n",
    "#---(Command to view headers of dataframe)\n",
    "\n",
    "## View/create a Pandas series \n",
    "#---print(df['Name of Header'])\n",
    "\n",
    "## Sort the dataframe\n",
    "#--- df = df.sort_values(by=['Column to sort by'], ascending=False)\n",
    "\n",
    "## Create another series based on the sort you just completed\n",
    "#--- name_your_series= df['Your Series']     \n",
    "\n",
    "## Print your Pandas series out\n",
    "#---(Command to print series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quesiton:\n",
    "What is the top 5 most retweeted tweets in the dataset? \n",
    "What tweet was viewed the most (received the most impressions)? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2 - Categorize entries as Tweet, Retweets, or Replies\n",
    "\n",
    "#Step 1) Import Libraries     - as done before\n",
    "#Step 2) Import Data          - as done before\n",
    "#Step 3) Group dataframe      - see below\n",
    "#Step 4) Print total elements - see below\n",
    "\n",
    "#Step 3) Created a grouped dataframe\n",
    "#--- name_of_dataframe_group = df.groupby(['Series to Group By'])\n",
    "\n",
    "#Step 4) Print number of elements of each group\n",
    "#--- apply .size() method to group object\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions: \n",
    "Did tweets consist of retweets, replies, or actual tweets?<br>\n",
    "What Language was used the most in the dataset? (English, Spanish, French, etc.)<br>\n",
    "Where most tweets verified or non-verified?<br>\n",
    "What operating system was used the most?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3 - Count the number of hashtags and plot\n",
    "#Step 1) Import libraries                 -as done before\n",
    "#Step 2) Import Data                      -as done before\n",
    "#Step 3) Create Series of Tweet content   -as done before\n",
    "#Step 4) Parse content for \"#\"            -see below \n",
    "#Step 5) Select the top 10                -see below\n",
    "#Step 6) Plot                             -see below\n",
    "\n",
    "#Step 4) Parse content for hashtag\n",
    "#We  will use regular expressions to parse through tweet content\n",
    "#--- apply .str.findall(r'string').explode() to series\n",
    "\n",
    "#Step 5) Get top 10 \n",
    "#--- top_10_hashtags=hashtags.value_counts().head(10)\n",
    "\n",
    "#Step 6) Plot using .plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question \n",
    "Is there enough information for you to confidently tell if shorter or longer hashtags used more?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 4 - Grouping by month\n",
    "\n",
    "#Step 1) Import libraries             - as done before \n",
    "#Step 2) Import Data                  - as done before \n",
    "#Step 3) UTC Time Series              - as done before \n",
    "#Step 4) Convert to year and month - see below\n",
    "#Step 5) Group & Sum appropriately    - see below\n",
    "#Step 6) Plot                         - as done before\n",
    "\n",
    "\n",
    "# Step 3) Append month series to dataframe\n",
    "#--- df['Month'] = pd.to_datetime(df['Tweet Posted Time (UTC)']).dt.strftime('%Y-%m')\n",
    "\n",
    "# Step 4 & 5) Sum up all the views on each date\n",
    "#--- month_totals = df.groupby(['Month']).sum()\n",
    "\n",
    "# Step 5) Plot using .plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Section 5) - Grouping by hour\n",
    "\n",
    "#Step 1) Import libraries             - as done before \n",
    "#Step 2) Import Data                  - as done before \n",
    "#Step 3) UTC-Time Series              - as done before \n",
    "#Step 4) Create Hour of Day Series    - see below\n",
    "#Step 5) Group & Sum appropriately    - as done before\n",
    "#Step 6) Plot                         - as done before\n",
    "\n",
    "# Step 4) Adding a new hour column\n",
    "#--df['Hour'] = pd.to_datetime(df['Tweet Posted Time (UTC)']).dt.strftime('%H')\n",
    "#--df['Hour_EST'] = (pd.to_numeric(df['Hour'] ) -4) % 24\n",
    "\n",
    "# Step 5) sum up all the views on each date\n",
    "#--hour_totals = df.groupby(['Hour_EST']).sum()\n",
    "\n",
    "#Step 6) Plot using .plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question\n",
    "How can you interpret the data?<br>\n",
    "Why do you think it has this shape?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
